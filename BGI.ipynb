{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["IfBORYcvyGGy","qtDsoL026Z2G","Rh04t4aD65eD","--s5uwxTZyPq","QPFoDbFg2Dq3","Z-reuIsGln39","3WPnqunf7Ony","c8iCJA6-QuO1"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Benchmark General Information Loader (BGI)**\n","\n","WHAT IT IS:\n","\n","- This script manages the creation and population of the BenchmarkGeneralInformation table\n","\n","- Benchmarks represent market indexes used to evaluate portfolio performance (e.g., VNQ, IYR, SCHH)\n","\n","\n","WHAT IT DOES:\n","\n","- Defines benchmark metadata (code, name, symbol, etc.) in a structured DataFrame\n","- Validates the schema and field types to ensure data consistency\n","- Uploads the data to a staging table in Snowflake\n","- Performs a MERGE operation to insert new benchmarks or update existing ones\n","\n","WHY IT'S IMPORTANT:\n","\n","- Benchmarks are essential for measuring portfolio returns against relevant market indices\n","- A clean and consistent BGI table allows for accurate performance attribution, reporting, and analysis\n","- The script is designed to be scalable, repeatable, and easy to extend with additional benchmarks"],"metadata":{"id":"F19M7OyNdFjb"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVt6CH8Y1tpp","executionInfo":{"status":"ok","timestamp":1753922052138,"user_tz":240,"elapsed":7401,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"9940e9fb-0e23-4d2d-d28c-984bc2aec1a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.12)\n","Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n","Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.12.0)\n","Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n","Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n","Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n","Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"]}],"source":["!pip install yfinance"]},{"cell_type":"markdown","source":["# **Benchmark General Information Table**\n"],"metadata":{"id":"IfBORYcvyGGy"}},{"cell_type":"markdown","source":["This table is meant to be static and can be updated via CSV. There is a proposed yaml file as an alternative to increase scalability, but it needs improvement."],"metadata":{"id":"05zu9-YPZX0Q"}},{"cell_type":"markdown","source":["## New Code"],"metadata":{"id":"qtDsoL026Z2G"}},{"cell_type":"code","source":["from pickle import FALSE  # Unused import – can be removed safely\n","import pandas as pd\n","\n","# Define static benchmark metadata entries\n","# Each dictionary represents a single benchmark and its key attributes\n","bgi_data = [\n","    {\n","        \"BENCHMARKCODE\": \"REITBENCH01\",\n","        \"NAME\": \"Vanguard Real Estate Index Fund ETF\",\n","        \"SYMBOL\": \"VNQ\",\n","        \"ISBEGINOFDAYPERFORMANCE\": False\n","    },\n","    {\n","        \"BENCHMARKCODE\": \"REITBENCH02\",\n","        \"NAME\": \"iShares US Real Estate ETF\",\n","        \"SYMBOL\": \"IYR\",\n","        \"ISBEGINOFDAYPERFORMANCE\": False\n","    },\n","    {\n","        \"BENCHMARKCODE\": \"REITBENCH03\",\n","        \"NAME\": \"Schwab US REIT ETF\",\n","        \"SYMBOL\": \"SCHH\",\n","        \"ISBEGINOFDAYPERFORMANCE\": False\n","    }\n","]\n","\n","# Convert the list of benchmark dictionaries into a pandas DataFrame\n","bgi_df = pd.DataFrame(bgi_data)\n","\n","# Output the final structured benchmark information\n","print(bgi_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0HgQO9jz6cHK","executionInfo":{"status":"ok","timestamp":1753924142405,"user_tz":240,"elapsed":44,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"f9611898-1312-4a25-9cdb-d560f2702cb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  BENCHMARKCODE                                 NAME SYMBOL  \\\n","0   REITBENCH01  Vanguard Real Estate Index Fund ETF    VNQ   \n","1   REITBENCH02           iShares US Real Estate ETF    IYR   \n","2   REITBENCH03                   Schwab US REIT ETF   SCHH   \n","\n","   ISBEGINOFDAYPERFORMANCE  \n","0                    False  \n","1                    False  \n","2                    False  \n"]}]},{"cell_type":"markdown","source":["## Validation"],"metadata":{"id":"Rh04t4aD65eD"}},{"cell_type":"code","source":["def assert_bgi(df):\n","    \"\"\"\n","    Validates the structure and integrity of a Benchmark General Information (BGI) DataFrame.\n","\n","    This function performs the following checks:\n","    1. Ensures that all required columns are present: 'BENCHMARKCODE', 'NAME', 'SYMBOL', 'ISBEGINOFDAYPERFORMANCE'.\n","    2. Ensures that the critical fields ('BENCHMARKCODE', 'NAME', 'SYMBOL') do not contain null values.\n","    3. Ensures that the 'ISBEGINOFDAYPERFORMANCE' column is of boolean dtype.\n","\n","    Parameters:\n","        df (pd.DataFrame): The BGI DataFrame to validate.\n","\n","    Raises:\n","        ValueError: If any required columns are missing or if null values are found in key fields.\n","        TypeError: If 'ISBEGINOFDAYPERFORMANCE' is not of boolean type.\n","\n","    Returns:\n","        None. Prints confirmation if validation passes.\n","    \"\"\"\n","    required_columns = {\"BENCHMARKCODE\", \"NAME\", \"SYMBOL\", \"ISBEGINOFDAYPERFORMANCE\"}\n","    actual_columns = set(df.columns)\n","\n","    # Check all required columns exist\n","    missing = required_columns - actual_columns\n","    if missing:\n","        raise ValueError(f\"Missing required BGI columns: {missing}\")\n","\n","    # Check for nulls in key fields\n","    nulls = df[[\"BENCHMARKCODE\", \"NAME\", \"SYMBOL\"]].isnull().any()\n","    for col, is_null in nulls.items():\n","        if is_null:\n","            raise ValueError(f\"Null values found in column: {col}\")\n","\n","    # Check boolean type\n","    if not pd.api.types.is_bool_dtype(df[\"ISBEGINOFDAYPERFORMANCE\"]):\n","        raise TypeError(\"ISBEGINOFDAYPERFORMANCE must be boolean\")\n","\n","    print(\"BGI validation passed.\")\n"],"metadata":{"id":"S3ZlTNPH61FB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## yaml version"],"metadata":{"id":"--s5uwxTZyPq"}},{"cell_type":"code","source":["import yaml\n","import pandas as pd\n","\n","def load_benchmark_config(yaml_path: str) -> pd.DataFrame:\n","    \"\"\"\n","    Loads benchmark metadata from a YAML configuration file and returns a pandas DataFrame.\n","\n","    Parameters:\n","        yaml_path (str): Path to the YAML file containing benchmark definitions.\n","\n","    Returns:\n","        pd.DataFrame: DataFrame with benchmark information, including BENCHMARKCODE, NAME,\n","                      SYMBOL, and ISBEGINOFDAYPERFORMANCE.\n","    \"\"\"\n","    with open(yaml_path, \"r\") as f:\n","        # Load list of benchmark dicts from the YAML file\n","        bgi_data = yaml.safe_load(f)\n","\n","    # Convert list of dictionaries to a DataFrame\n","    return pd.DataFrame(bgi_data)\n","\n","# Example usage:\n","# bgi_df = load_benchmark_config(\"benchmarks.yaml\")\n","# print(bgi_df)\n"],"metadata":{"id":"0z4mxD-iZ03h","executionInfo":{"status":"ok","timestamp":1754081544545,"user_tz":240,"elapsed":7,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# **Connecting to Snowflake**"],"metadata":{"id":"QPFoDbFg2Dq3"}},{"cell_type":"markdown","source":["## Establishing Connection"],"metadata":{"id":"Z-reuIsGln39"}},{"cell_type":"markdown","source":["You must download the env.txt file which is located in Github (env.txt) and upload using the \"Choose Files\" widget after running the below cell."],"metadata":{"id":"aCaqWuKnfCMD"}},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"oOwM03pkkw8y","executionInfo":{"status":"ok","timestamp":1753922433440,"user_tz":240,"elapsed":4597,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"b3761e34-7125-4324-b936-deeeec9e3fc8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-fb1f188d-2022-42f5-8a18-46a4f0e81be0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-fb1f188d-2022-42f5-8a18-46a4f0e81be0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving env.txt to env.txt\n"]}]},{"cell_type":"code","source":["import os\n","\n","if os.path.exists(\"env.txt\"):\n","    os.rename(\"env.txt\", \"env\")\n","    print(\"Renamed env.txt to env\")\n","else:\n","    print(\"File not found. Make sure you uploaded env.txt.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOoYQafKk7vQ","executionInfo":{"status":"ok","timestamp":1753922434977,"user_tz":240,"elapsed":12,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"11daf485-8e7f-4a5d-8961-79cfc4f0ff5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Renamed env.txt to env\n"]}]},{"cell_type":"code","source":["!pip install snowflake-connector-python python-dotenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPbMHknlk_L7","executionInfo":{"status":"ok","timestamp":1753922449537,"user_tz":240,"elapsed":13725,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"a98aaa24-ea25-4568-d0c8-2bf2e0bee987"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting snowflake-connector-python\n","  Downloading snowflake_connector_python-3.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (71 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv\n","  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n","Collecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python)\n","  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting boto3>=1.24 (from snowflake-connector-python)\n","  Downloading boto3-1.39.17-py3-none-any.whl.metadata (6.7 kB)\n","Collecting botocore>=1.24 (from snowflake-connector-python)\n","  Downloading botocore-1.39.17-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (1.17.1)\n","Requirement already satisfied: cryptography>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (43.0.3)\n","Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (24.2.1)\n","Requirement already satisfied: pyjwt<3.0.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2.10.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2025.2)\n","Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2.32.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (25.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2025.7.14)\n","Requirement already satisfied: typing_extensions<5,>=4.3 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (4.14.1)\n","Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (3.18.0)\n","Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (2.4.0)\n","Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (4.3.8)\n","Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from snowflake-connector-python) (0.13.3)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.24->snowflake-connector-python)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.24->snowflake-connector-python)\n","  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.24->snowflake-connector-python) (2.9.0.post0)\n","Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore>=1.24->snowflake-connector-python) (2.5.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.24->snowflake-connector-python) (1.17.0)\n","Downloading snowflake_connector_python-3.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n","Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.39.17-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading botocore-1.39.17-py3-none-any.whl (13.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: asn1crypto, python-dotenv, jmespath, botocore, s3transfer, boto3, snowflake-connector-python\n","Successfully installed asn1crypto-1.5.1 boto3-1.39.17 botocore-1.39.17 jmespath-1.0.1 python-dotenv-1.1.1 s3transfer-0.13.1 snowflake-connector-python-3.16.0\n"]}]},{"cell_type":"code","source":["from dotenv import load_dotenv\n","load_dotenv(\"env\")  # This loads the Snowflake credentials into the environment"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-e_ija5ylBIe","executionInfo":{"status":"ok","timestamp":1753922449633,"user_tz":240,"elapsed":94,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"2c394702-c623-443a-86aa-d3dea3c292fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import snowflake.connector\n","import os\n","\n","# Pull in credentials\n","conn = snowflake.connector.connect(\n","    user=os.getenv(\"SNOWFLAKE_USER\"),\n","    password=os.getenv(\"SNOWFLAKE_PASSWORD\"),\n","    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n","    role=os.getenv(\"SNOWFLAKE_ROLE\"),\n","    warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n","    database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n","    schema=os.getenv(\"SNOWFLAKE_SCHEMA\")\n",")\n","\n","# Run a simple test query\n","cur = conn.cursor()\n","cur.execute(\"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_DATABASE();\")\n","for row in cur:\n","    print(row)\n","\n","cur.close()\n","conn.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80emU-fllD84","executionInfo":{"status":"ok","timestamp":1753922453726,"user_tz":240,"elapsed":1979,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"8ca87d7b-d7fa-4704-92b5-ea655b82b283"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('SHIVNEETN', 'AST_REALESTATE_DB_RW', 'AST_REALESTATE_DB')\n"]}]},{"cell_type":"markdown","source":["## Populating BGI in Snowflake"],"metadata":{"id":"3WPnqunf7Ony"}},{"cell_type":"code","source":["from snowflake.connector import connect\n","from snowflake.connector.pandas_tools import write_pandas\n","import os\n","import pandas as pd\n","\n","# Optional: run validation first\n","# from assert_bgi import assert_bgi\n","# assert_bgi(bgi_df)\n","\n","# Connect to Snowflake\n","conn = connect(\n","    user=os.getenv(\"SNOWFLAKE_USER\"),\n","    password=os.getenv(\"SNOWFLAKE_PASSWORD\"),\n","    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n","    role=os.getenv(\"SNOWFLAKE_ROLE\"),\n","    warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n","    database=\"AST_REALESTATE_DB\",\n","    schema=\"DBO\"\n",")\n","\n","# Ensure correct schema\n","with conn.cursor() as cur:\n","    cur.execute(\"USE DATABASE AST_REALESTATE_DB\")\n","    cur.execute(\"USE SCHEMA DBO\")\n","\n","    # Create staging table (temporary or permanent depending on your process)\n","    cur.execute(\"\"\"\n","        CREATE OR REPLACE TEMP TABLE STG_BENCHMARKGENERALINFORMATION (\n","            BENCHMARKCODE VARCHAR,\n","            NAME VARCHAR,\n","            SYMBOL VARCHAR,\n","            ISBEGINOFDAYPERFORMANCE BOOLEAN\n","        )\n","    \"\"\")\n","\n","# Upload to staging\n","success, nchunks, nrows, _ = write_pandas(\n","    conn, df=bgi_df, table_name=\"STG_BENCHMARKGENERALINFORMATION\", quote_identifiers=False\n",")\n","print(f\"Uploaded {nrows} rows to STG_BENCHMARKGENERALINFORMATION\")\n","\n","# MERGE into target table\n","with conn.cursor() as cur:\n","    cur.execute(\"\"\"\n","        MERGE INTO BenchmarkGeneralInformation AS target\n","        USING STG_BENCHMARKGENERALINFORMATION AS source\n","        ON target.BENCHMARKCODE = source.BENCHMARKCODE\n","\n","        WHEN MATCHED THEN UPDATE SET\n","            target.NAME = source.NAME,\n","            target.SYMBOL = source.SYMBOL,\n","            target.ISBEGINOFDAYPERFORMANCE = source.ISBEGINOFDAYPERFORMANCE\n","\n","        WHEN NOT MATCHED THEN INSERT (\n","            BENCHMARKCODE, NAME, SYMBOL, ISBEGINOFDAYPERFORMANCE\n","        ) VALUES (\n","            source.BENCHMARKCODE, source.NAME, source.SYMBOL, source.ISBEGINOFDAYPERFORMANCE\n","        )\n","    \"\"\")\n","    print(\"MERGE into BenchmarkGeneralInformation completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70Rl9_di7Mww","executionInfo":{"status":"ok","timestamp":1753924158934,"user_tz":240,"elapsed":5084,"user":{"displayName":"Shivneet Nag","userId":"14807483772028410046"}},"outputId":"ae5c4485-efa7-47fc-92df-22d98fe5791d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Uploaded 3 rows to STG_BENCHMARKGENERALINFORMATION\n","MERGE into BenchmarkGeneralInformation completed.\n"]}]},{"cell_type":"markdown","source":["# **Data Flow & Architecture Mapping**"],"metadata":{"id":"c8iCJA6-QuO1"}},{"cell_type":"markdown","source":["## Source to Storage Mapping"],"metadata":{"id":"Lq-Wvxp7Q3VR"}},{"cell_type":"markdown","source":["| Stage                        | Description                                                                                             |\n","| ---------------------------- | ------------------------------------------------------------------------------------------------------- |\n","| **Source**                   | Manual inputs or internal static mapping of REIT benchmarks (`SYMBOL`, `NAME`, `BENCHMARKCODE`)         |\n","| **Extraction**               | Loaded into Python as `bgi_df` via Excel seed, Snowflake query, or hardcoded config                     |\n","| **Transformation**           | Minor cleaning to standardize `SYMBOL`, ensure valid tickers, and tag with `ISBEGINOFDAYPERFORMANCE`    |\n","|  • `symbol.strip()`          | Removes special characters like `$`, extra spaces for compatibility with Yahoo Finance                  |\n","|  • `name.title()`            | Normalizes benchmark names                                                                              |\n","|  • `map benchmark code`      | Assigns fixed codes: `REITBENCH001`, `REITBENCH002`, etc.                                               |\n","|  • `ISBEGINOFDAYPERFORMANCE` | Set to `True` to indicate NAV-style processing                                                          |\n","| **Validation**               | `assert_bgi()` or manual assertions validate required fields and naming patterns                        |\n","| **Storage**                  | Uploaded to `STG_BENCHMARKGENERALINFORMATION` → `MERGE`d into final `BenchmarkGeneralInformation` table |\n","| **Consumption**              | Used to drive benchmark universe, match to performance series, power UI dropdowns & audits              |\n"],"metadata":{"id":"AxsOclIRQ5Zc"}},{"cell_type":"markdown","source":["## Data Flow Diagram"],"metadata":{"id":"xjm6SnQHQ8Om"}},{"cell_type":"markdown","source":["          +--------------------------+\n","          | Local Seed (Excel/JSON) |\n","          +--------------------------+\n","                      |\n","          [pd.read_excel() or manual entry]\n","                      |\n","                      v\n","         +-------------------------------+\n","         | Clean + Format bgi_df         |\n","         | - symbol.strip()              |\n","         | - name.title()                |\n","         | - assign ISBEGINOFDAYPERFORMANCE |\n","         +-------------------------------+\n","                      |\n","                      v\n","         +-------------------------------+\n","         | Optional: assert_bgi()        |\n","         | - Check for missing values    |\n","         | - Valid symbol formatting     |\n","         +-------------------------------+\n","                      |\n","                      v\n","         +-------------------------------+\n","         | write_pandas() to staging     |\n","         | STG_BENCHMARKGENERALINFORMATION |\n","         +-------------------------------+\n","                      |\n","                      v\n","         +-------------------------------+\n","         | MERGE into BGI table          |\n","         +-------------------------------+\n","                      |\n","                      v\n","         +-------------------------------+\n","         | Used by benchmark engine, UI  |\n","         +-------------------------------+\n"],"metadata":{"id":"bW-df2YpQ_TP"}},{"cell_type":"markdown","source":["## Transformation Logic Documentation"],"metadata":{"id":"y-HJBmCzRGZS"}},{"cell_type":"markdown","source":["### Symbol"],"metadata":{"id":"mezsMySXRJXt"}},{"cell_type":"markdown","source":["| Transformation | Description                                                           |\n","| -------------- | --------------------------------------------------------------------- |\n","| Strip prefix   | Removes `$` or whitespace from symbols (e.g., `\"$VNQ\"` → `\"VNQ\"`)     |\n","| Validation     | Ensures symbol is compatible with Yahoo Finance (`yf.Ticker(symbol)`) |\n","| Type           | `VARCHAR` — must be valid for external data pulls                     |\n"],"metadata":{"id":"ywgYzDYnRMEk"}},{"cell_type":"markdown","source":["### BenchmarkCode"],"metadata":{"id":"MONN83_nRNnJ"}},{"cell_type":"markdown","source":["| Transformation | Description                                                         |\n","| -------------- | ------------------------------------------------------------------- |\n","| Manual mapping | Fixed assignments: `VNQ → REITBENCH001`, `IYR → REITBENCH002`, etc. |\n","| Uniqueness     | Primary key in final table                                          |\n","| Type           | `VARCHAR` — follows naming standard `REITBENCH###`                  |\n"],"metadata":{"id":"xVT3qjfaRRsQ"}},{"cell_type":"markdown","source":["### Name"],"metadata":{"id":"JRWnp7n2RTbp"}},{"cell_type":"markdown","source":["| Transformation | Description                                  |\n","| -------------- | -------------------------------------------- |\n","| Title case     | Standardized (e.g., `\"Vanguard REIT Index\"`) |\n","| Validation     | Should match symbol’s ETF/fund description   |\n","| Type           | `VARCHAR`                                    |\n"],"metadata":{"id":"R9q5tAvpRVXT"}},{"cell_type":"markdown","source":["### IsBeginOfDayPerformance"],"metadata":{"id":"J9FIXIVORdDH"}},{"cell_type":"markdown","source":["| Transformation | Description                                              |\n","| -------------- | -------------------------------------------------------- |\n","| Default value  | Always `True` for NAV-style or adjusted price series     |\n","| Purpose        | Tells downstream logic how to time-align with portfolios |\n","| Type           | `BOOLEAN`                                                |\n"],"metadata":{"id":"3qp54-zYRgQQ"}},{"cell_type":"markdown","source":["### Validation"],"metadata":{"id":"iqLsDSWlRhra"}},{"cell_type":"markdown","source":["| Check                 | Description                                                                  |\n","| --------------------- | ---------------------------------------------------------------------------- |\n","| Required fields       | `BENCHMARKCODE`, `SYMBOL`, `NAME`, `ISBEGINOFDAYPERFORMANCE` must be present |\n","| Valid ticker format   | Symbols must resolve in `yfinance` or mapped correctly                       |\n","| Unique benchmark code | No duplicates allowed                                                        |\n","| Optional integration  | Could cross-validate symbols against a live ETF ticker list                  |\n"],"metadata":{"id":"W59wjNDHRj4o"}},{"cell_type":"markdown","source":["## Future Enhancements"],"metadata":{"id":"9PfPC7ChRlmT"}},{"cell_type":"markdown","source":["| Feature               | Description                                                                    |\n","| --------------------- | ------------------------------------------------------------------------------ |\n","| Benchmark Category    | Add `CATEGORY` column (e.g., `REIT`, `Equity`, `Fixed Income`)                 |\n","| Inception Date        | Add date metadata for benchmark tracking start                                 |\n","| Override System       | Introduce manual flag for symbol suppression or rerouting                      |\n","| Symbol Health Monitor | Automated `yfinance` ping to validate ticker availability                      |\n","| Benchmark Type Enum   | Formalize NAV-based vs. price-based benchmarks (`Total Return`, `Price`, etc.) |\n","| CI Integration        | Add pre-merge validation in a CI pipeline                                      |\n"],"metadata":{"id":"vEXx9QNwRnU0"}}]}
