# -*- coding: utf-8 -*-
"""Holdings Details.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-EQtrw6uQXx6M8oJ2w0ScYYIYh0CaedY

# Holdings Details

## Creating New Table

### Snowflake
"""

!pip install snowflake-connector-python

import pandas as pd
import snowflake.connector

# Connect to Snowflake
conn = snowflake.connector.connect(
    user="ZICHENGW",
    password="Chinazcw08624@@",
    account="assette-ssappoc",
    role="AST_REALESTATE_DB_RW",
    warehouse="AST_BU_WH",  # Use the active/suspended warehouse shown
    database="AST_REALESTATE_DB",
    schema="DBO"
)

# SQL Query to load table
query = "SELECT * FROM SECURITY_MASTER"

# Execute and load into DataFrame
df_security_master = pd.read_sql(query, conn)

# Show preview
print(df_security_master.head())

# Close connection
conn.close()

# Display all rows and columns
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

# Display full SECURITY_MASTER table
display(df_security_master)

"""### Data"""

!pip install yfinance

tickers = df_security_master["TICKER"].dropna().unique().tolist()
print(tickers)

"""**New Table**"""

import pandas as pd
import yfinance as yf
from datetime import datetime
import random
import string
import snowflake.connector
import logging

# Silence yfinance logs
logging.getLogger("yfinance").setLevel(logging.CRITICAL)

# Step 1: Load SECURITY_MASTER from Snowflake
conn = snowflake.connector.connect(
    user="ZICHENGW",
    password="Chinazcw08624@@",
    account="assette-ssappoc",
    role="AST_REALESTATE_DB_RW",
    warehouse="AST_BU_WH",
    database="AST_REALESTATE_DB",
    schema="DBO"
)
sec_df = pd.read_sql("SELECT * FROM SECURITY_MASTER", conn)
conn.close()

sec_df["TICKER"] = sec_df["TICKER"].str.upper()
tickers_all = sec_df["TICKER"].dropna().unique().tolist()

# Step 2: Ticker-to-Portfolio assignment
portfolios = {
    "REITPORTFOLIO001": "Core U.S. Equity REITs",
    "REITPORTFOLIO002": "Real Estate Services & Platforms",
    "REITPORTFOLIO003": "Global Real Estate Diversified",
    "REITPORTFOLIO004": "Mortgage & Hybrid REITs",
    "REITPORTFOLIO005": "Industrial, Retail & Infrastructure"
}

ticker_to_portfolio_map = {}
for _, row in sec_df.iterrows():
    ticker = row["TICKER"]
    industry = str(row.get("INDUSTRY", "")).lower()
    sector = str(row.get("SECTOR", "")).lower()
    if "mortgage" in industry or "hybrid" in industry:
        ticker_to_portfolio_map[ticker] = "REITPORTFOLIO004"
    elif "service" in industry or "platform" in industry:
        ticker_to_portfolio_map[ticker] = "REITPORTFOLIO002"
    elif "industrial" in industry or "retail" in industry or "infrastructure" in industry:
        ticker_to_portfolio_map[ticker] = "REITPORTFOLIO005"
    elif "global" in sector:
        ticker_to_portfolio_map[ticker] = "REITPORTFOLIO003"
    else:
        ticker_to_portfolio_map[ticker] = "REITPORTFOLIO001"

# Step 3: Helper functions
def random_isin(ticker):
    return f"US{random.randint(100000000, 999999999)}"

def industry_group_mapping(industry):
    if not isinstance(industry, str): return "REIT"
    ind = industry.lower()
    if "residential" in ind:
        return "Real Estate"
    elif "retail" in ind:
        return "Retail"
    elif "industrial" in ind:
        return "Industrials"
    elif "data" in ind:
        return "Infrastructure"
    else:
        return "REIT"

# Step 4: Column structure
column_names = [
    "PORTFOLIOCODE", "CURRENCYCODE", "CURRENCY", "LANGUAGECODE", "ISSUERNAME", "ISSUENAME",
    "ISSUEDISPLAYNAME", "COSTBASIS", "QUANTITY", "MARKETVALUEWITHOUTACCRUEDINCOME",
    "ACCRUEDINCOME", "MARKETVALUE", "LOCALMARKETVALUE", "UNREALIZEDGAINSLOSSES",
    "DIVIDENDYIELD", "ESTIMATEDANNUALINCOME", "HOLDINGSPERIOD", "PORTFOLIOWEIGHT",
    "PRICE", "BOOKVALUE", "LOCALBOOKVALUE", "ASSETCLASSNAME", "ISSUETYPE", "ISINCODE",
    "CUSIP", "FIGIID", "TICKER", "RISKCOUNTRYCODE", "RISKCOUNTRY", "HQCOUNTRYCODE",
    "HQCOUNTRY", "ISSUECOUNTRYCODE", "ISSUECOUNTRY", "HISTORYDATE", "SECTOR", "INDUSTRY",
    "COUNTRY", "PRIMARYSECTORNAME", "PRIMARYINDUSTRYNAME", "PRIMARYINDUSTRYGROUPNAME",
    "PRIMARYSUBINDUSTRYNAME", "REGIONNAME", "REGIONCLASSIFICATIONSCHEME",
    "PRIMARYSECTORSCHEME", "PRIMARYSUBSECTORNAME", "SECONDARYSECTORSCHEME",
    "SECONDARYSECTORNAME", "SECONDARYSUBSECTORNAME", "SECONDARYINDUSTRYGROUPNAME",
    "SECONDARYINDUSTRYNAME", "SECONDARYSUBINDUSTRYNAME", "CUSTOMCLASSIFICATION1",
    "CUSTOMCLASSIFICATION1NAME", "CUSTOMCLASSIFICATION2", "CUSTOMCLASSIFICATION2NAME",
    "CUSTOMCLASSIFICATION3", "CUSTOMCLASSIFICATION3NAME", "CUSTOMCLASSIFICATION4",
    "CUSTOMCLASSIFICATION4NAME", "CUSTOMCLASSIFICATION5", "CUSTOMCLASSIFICATION5NAME",
    "CUSTOMCLASSIFICATION6", "CUSTOMCLASSIFICATION6NAME", "ABBREVIATEDTEXT"
]

# Step 5: Generate synthetic holdings records
records = []
skipped_tickers = []

for _, row in sec_df.iterrows():
    ticker = row["TICKER"]
    try:
        t = yf.Ticker(ticker)
        hist = t.history(period="1d")
        if hist.empty:
            hist = t.history(period="5d")
        if hist.empty or "Close" not in hist or hist["Close"].dropna().empty:
            skipped_tickers.append(ticker)
            continue

        price = hist["Close"].dropna().iloc[-1]
        if price is None or price == 0:
            skipped_tickers.append(ticker)
            continue

        info = t.info
        quantity = 100
        dividend_yield = info.get("dividendYield", 0.04)

        # FIXED: Use 98% of current price as cost basis (deterministic)
        cost_basis = round(price * 0.98, 2)

        market_value = round(price * quantity, 2)
        book_value = round(cost_basis * quantity, 2)
        accrued_income = round(market_value * 0.01, 2)  # Approximate 1% accrued income
        mv_wo_accrued = round(market_value - accrued_income, 2)
        unrealized_gain = round(market_value - book_value, 2)
        est_annual_income = round(market_value * dividend_yield, 2)

        # FIXED: Use real CUSIP if available
        cusip_value = info.get("cusip", "")

        # FIXED: Correct naming
        issuer_name = info.get("longName") or info.get("shortName") or ticker
        issue_name = f"{issuer_name} Common Stock"
        issue_display_name = issue_name

        record = dict.fromkeys(column_names, "")
        record.update({
            "TICKER": ticker,
            "PORTFOLIOCODE": ticker_to_portfolio_map.get(ticker, "REITPORTFOLIO999"),
            "PRICE": price,
            "COSTBASIS": cost_basis,
            "BOOKVALUE": book_value,
            "MARKETVALUE": market_value,
            "LOCALMARKETVALUE": market_value,
            "ACCRUEDINCOME": accrued_income,
            "MARKETVALUEWITHOUTACCRUEDINCOME": mv_wo_accrued,
            "UNREALIZEDGAINSLOSSES": unrealized_gain,
            "DIVIDENDYIELD": round(dividend_yield * 100, 2),
            "ESTIMATEDANNUALINCOME": est_annual_income,
            "QUANTITY": quantity,
            "CURRENCY": "USD",
            "CURRENCYCODE": "USD",
            "LANGUAGECODE": "EN",

            # Fixed naming here
            "ISSUERNAME": issuer_name,
            "ISSUENAME": issue_name,
            "ISSUEDISPLAYNAME": issue_display_name,

            "SECTOR": "Real Estate",
            "INDUSTRY": "REIT",
            "COUNTRY": "United States",
            "HISTORYDATE": datetime.today().date(),
            "ISINCODE": random_isin(ticker),
            "CUSIP": cusip_value,
            "ISSUETYPE": "REIT Equity",
            "RISKCOUNTRY": "United States",
            "RISKCOUNTRYCODE": "US",
            "ISSUECOUNTRY": "United States",
            "ISSUECOUNTRYCODE": "US",
            "HQCOUNTRY": "United States",
            "HQCOUNTRYCODE": "US",
            "PRIMARYSECTORNAME": row.get("SECTOR", "Real Estate"),
            "PRIMARYINDUSTRYNAME": row.get("INDUSTRY", "REIT"),
            "PRIMARYINDUSTRYGROUPNAME": industry_group_mapping(row.get("INDUSTRY", "")),
            "PRIMARYSUBINDUSTRYNAME": "REIT",
            "REGIONNAME": "North America",
            "REGIONCLASSIFICATIONSCHEME": "GICS"
        })
        records.append(record)
    except Exception:
        skipped_tickers.append(ticker)
        continue

# Step 6: Output
df_final = pd.DataFrame(records, columns=column_names)
filename = f"REIT_Holdings_{datetime.today().strftime('%Y-%m-%d')}.csv"
df_final.to_csv(filename, index=False)

print(df_final.head(10))
print(f"\n Saved successfully to '{filename}'. Total holdings: {len(df_final)}")
if skipped_tickers:
    print(f" Skipped {len(skipped_tickers)} tickers. Examples: {skipped_tickers[:10]}")

"""### Financial Calculation Explanations

The financial calculations are consistent with standard definitions from trusted sources like **Investopedia**. Here's how each line aligns with common investment principles:

---

**Financial Calculation Explanations (Aligned with Investopedia)**

---

**1.** `dividend_yield = info.get("dividendYield", 0.04)`

* **Matches:** [Dividend Yield – Investopedia](https://www.investopedia.com/terms/d/dividendyield.asp)
* **Definition:**

  > *Dividend per share ÷ Price per share*
* **Usage in code:**
  Pulled directly from Yahoo Finance (`t.info`). A default of 4% is used only when missing. This reflects typical REIT payout behavior.

---

**2.** `cost_basis = round(price * 0.98, 2)`

* **Matches:** [Cost Basis – Investopedia](https://www.investopedia.com/terms/c/costbasis.asp)
* **Definition:**

  > *The original value (purchase price) of an asset for tax purposes.*
* **Usage in code:**
  Now fixed at **98% of the current market price** to simulate a realistic acquisition price with a slight historical discount — assuming a single long-term buy-and-hold entry.

---

**3.** `market_value = round(price * quantity, 2)`

* **Matches:** [Market Value – Investopedia](https://www.investopedia.com/terms/m/marketvalue.asp)
* **Definition:**

  > *Current price × number of shares owned*
* **Usage in code:**
  This is the direct fair market value of holdings. Correctly implemented.

---

**4.** `book_value = round(cost_basis * quantity, 2)`

* **Matches:** [Book Value – Investopedia](https://www.investopedia.com/terms/b/bookvalue.asp)
* **Definition (for portfolio holdings):**

  > *Purchase cost × quantity held (original capital invested)*
* **Usage in code:**
  Reflects the total amount spent to acquire the asset. Accurately calculated.

---

**5.** `accrued_income = round(market_value * 0.01, 2)`

* **Matches:** [Accrued Interest – Investopedia](https://www.investopedia.com/terms/a/accruedinterest.asp)
* **Definition:**

  > *Income that has been earned but not yet paid.*
* **Usage in code:**
  Assumes 1% of the holding's value has accrued in unpaid dividends. This is a REIT-appropriate simplification for interest/dividend accrual.

---

**6.** `mv_wo_accrued = round(market_value - accrued_income, 2)`

* **Interpretation:**

  > *Net Market Value* — excludes income not yet received. Useful in assessing pure capital value without yield assumptions.

---

**7.** `unrealized_gain = round(market_value - book_value, 2)`

* **Matches:** [Unrealized Gain – Investopedia](https://www.investopedia.com/terms/u/unrealizedgain.asp)
* **Definition:**

  > *The increase in value of a currently held investment that has not yet been sold for profit.*
* **Usage in code:**
  Straightforward difference between market and book value.

---

**8.** `est_annual_income = round(market_value * dividend_yield, 2)`

* **Matches:**

  > *Annual cash flow estimation based on dividend yield*
* **Usage in code:**
  This represents projected yearly dividends based on the current market value and payout ratio — standard financial modeling practice.

---

**9.** `cusip_value = info.get("cusip", "")`

* **Matches:** [CUSIP Number – Investopedia](https://www.investopedia.com/terms/c/cusip.asp)
* **Definition:**

  > *A unique identifier assigned to securities to facilitate clearing and settlement.*
* **Usage in code:**
  Correctly retrieves CUSIP from Yahoo Finance. Skips the prior use of fake or randomly generated codes, aligning the dataset with real financial identifiers.

---

**Final Verdict:**

All financial logic in the code is **consistent with standard investment formulas** used on Investopedia. The changes make the holdings simulation:

* **More accurate**
* **Less arbitrary**
* **More auditable for future scaling** (e.g., storing historical cost basis, pricing snapshots, or verified CUSIPs).

### Validation
"""

import pandas as pd
import yfinance as yf
from datetime import datetime
import logging
import re

# --------------------------
# Setup Logging
# --------------------------
logging.basicConfig(
    filename="validation_log.txt",
    filemode="w",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logging.info("=== REIT DATA VALIDATION STARTED ===")

# --------------------------
# Load Holdings File
# --------------------------
today_str = datetime.today().strftime('%Y-%m-%d')
filename = f"REIT_Holdings_{today_str}.csv"

try:
    df = pd.read_csv(filename)
    logging.info(f"File '{filename}' loaded successfully. Rows: {len(df)}")
except FileNotFoundError:
    logging.error(f"File '{filename}' not found.")
    raise

# --------------------------
# TICKER Format Check
# --------------------------
invalid_tickers = df[~df["TICKER"].astype(str).str.match(r"^[A-Z]{1,5}$", na=False)]
if not invalid_tickers.empty:
    logging.warning("Invalid ticker format detected:")
    logging.warning(invalid_tickers["TICKER"].to_list())

# --------------------------
# Missing Values Check
# --------------------------
nulls = df.isnull().sum()
null_columns = nulls[nulls > 0]
if not null_columns.empty:
    logging.warning("Missing values found:")
    for col, count in null_columns.items():
        logging.warning(f"- {col}: {count} missing")

# --------------------------
# Non-Positive Price Check
# --------------------------
non_positive_price = df[df["PRICE"] <= 0]
if not non_positive_price.empty:
    logging.warning("Tickers with non-positive PRICE:")
    logging.warning(non_positive_price[["TICKER", "PRICE"]].to_string(index=False))

# --------------------------
# Dividend Yield Check
# --------------------------
df["DIVIDENDYIELD"] = pd.to_numeric(df["DIVIDENDYIELD"], errors="coerce")
yield_issues = df[
    (df["DIVIDENDYIELD"].isnull()) |
    (df["DIVIDENDYIELD"] < 0) |
    (df["DIVIDENDYIELD"] > 15)
]
if not yield_issues.empty:
    logging.warning("Unusual or missing dividend yields:")
    logging.warning(yield_issues[["TICKER", "DIVIDENDYIELD"]].to_string(index=False))

# --------------------------
# SECTOR Consistency Check
# --------------------------
non_reit_sector = df[~df["SECTOR"].astype(str).str.contains("Real Estate", na=False)]
if not non_reit_sector.empty:
    logging.warning("Tickers NOT classified under 'Real Estate' sector:")
    logging.warning(non_reit_sector[["TICKER", "SECTOR"]].to_string(index=False))

# --------------------------
# Duplicate Ticker Check
# --------------------------
dupes = df[df.duplicated("TICKER", keep=False)]
if not dupes.empty:
    logging.warning("Duplicate tickers found:")
    logging.warning(dupes["TICKER"].to_list())

# --------------------------
# Yahoo Finance Price Check
# --------------------------
price_mismatches = []
for _, row in df.iterrows():
    ticker = row["TICKER"]
    try:
        t = yf.Ticker(ticker)
        hist = t.history(period="1d")
        if hist.empty:
            hist = t.history(period="5d")
        if hist.empty or "Close" not in hist or hist["Close"].dropna().empty:
            logging.warning(f"Ticker {ticker}: No valid price data from Yahoo Finance.")
            continue

        yahoo_price = hist["Close"].dropna().iloc[-1]
        local_price = row["PRICE"]

        if abs(yahoo_price - local_price) / yahoo_price > 0.10:
            price_mismatches.append((ticker, local_price, yahoo_price))

    except Exception as e:
        logging.error(f"Error retrieving {ticker} from Yahoo: {str(e)}")

if price_mismatches:
    logging.warning("Tickers with >10% PRICE mismatch vs Yahoo Finance:")
    for tkr, local, yahoo in price_mismatches:
        logging.warning(f"{tkr}: Local={local}, Yahoo={yahoo:.2f}")

# --------------------------
# End
# --------------------------
logging.info("=== REIT DATA VALIDATION ENDED ===")

"""### Real-time exchange rate

**Run this code to get the latest exchange rates**
"""

import yfinance as yf
import pandas as pd
from datetime import datetime
import os

# Step 1: Clean list of valid Yahoo Finance currency symbols
currency_pairs = [
    "EURUSD=X", "USDGBP=X", "USDJPY=X", "USDAUD=X", "USDCAD=X",
    "USDCHF=X", "USDMXN=X", "JPYEUR=X", "AUDEUR=X", "JPYGBP=X"
]

# Step 2: Prepare results
results = []
history_date = datetime.today().strftime('%Y-%m-%d')

# Step 3: Fetch and store data
for symbol in currency_pairs:
    try:
        data = yf.Ticker(symbol)
        info = data.info
        hist = data.history(period="1d")

        if hist.empty:
            continue

        row = hist.iloc[-1]
        current_price = row['Close']
        percent_change = info.get("regularMarketChangePercent", 0)
        previous_close = current_price / (1 + percent_change / 100) if percent_change else current_price

        results.append({
            "symbol": symbol,
            "name": info.get("shortName", symbol),
            "history_date": history_date,
            "current_price": round(current_price, 6),
            "previous_close": round(previous_close, 6),
            "day_change": round(current_price - previous_close, 6),
            "day_change_percent": round(percent_change, 4),
            "bid": info.get("bid", 0),
            "ask": info.get("ask", 0),
            "52_week_high": info.get("fiftyTwoWeekHigh", 0),
            "52_week_low": info.get("fiftyTwoWeekLow", 0),
            "volume": info.get("volume", 0)
        })

    except Exception as e:
        print(f"Error fetching {symbol}: {e}")

# Step 4: Convert to DataFrame
df_currency = pd.DataFrame(results)

# Step 5: Display
print("============================================")
print("           CURRENCY DATA TABLE              ")
print("============================================")
print(df_currency.to_string(index=False))

# Step 6: Ensure output folder exists and save
os.makedirs("data/output", exist_ok=True)
output_path = f"data/output/currency_data_{datetime.today().strftime('%Y%m%d_%H%M%S')}.csv"
df_currency.to_csv(output_path, index=False)
print(f"Data saved to: {output_path}")

"""## Connecting to Snowflake

### Confirm New Table
"""

df_final  # This is the holdings data

"""### Connecting to Snowflake **(Don't Run Again)**"""

pip install snowflake-connector-python python-dotenv

from google.colab import files
uploaded = files.upload()

import snowflake.connector
from dotenv import load_dotenv
import os

# Load environment variables from .env file
load_dotenv()

# Connect to Snowflake using variables in .env
conn = snowflake.connector.connect(
    user=os.getenv("SNOWFLAKE_USER", "ZICHENGW"),
    password=os.getenv("SNOWFLAKE_PASSWORD", "Chinazcw08624@@"),
    account=os.getenv("SNOWFLAKE_ACCOUNT", "assette-ssappoc"),
    role=os.getenv("SNOWFLAKE_ROLE", "AST_REALESTATE_DB_RW"),
    warehouse=os.getenv("SNOWFLAKE_WAREHOUSE", "AST_BU_WH"),
    database=os.getenv("SNOWFLAKE_DATABASE", "AST_REALESTATE_DB"),
    schema=os.getenv("SNOWFLAKE_SCHEMA", "DBO")
)

# Validate connection
cur = conn.cursor()
cur.execute("SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_DATABASE();")
print("Connection successful:", cur.fetchall())

# Close
cur.close()
conn.close()

import pandas as pd
import snowflake.connector
import numpy as np

# Step 1: Load the new CSV
df = pd.read_csv("REIT_Holdings_2025-08-05.csv")
print("✅ Loaded new holdings data:", df.shape)

# Step 2: Normalize column names (strip whitespace)
df.columns = df.columns.str.strip()

# Step 3: Replace NaNs with None (Snowflake compatibility)
df.replace({np.nan: None}, inplace=True)

# Step 4: Connect to Snowflake
conn = snowflake.connector.connect(
    user="ZICHENGW",
    password="Chinazcw08624@@",
    account="assette-ssappoc",
    role="AST_REALESTATE_DB_RW",
    warehouse="AST_BU_WH",
    database="AST_REALESTATE_DB",
    schema="DBO"
)
cur = conn.cursor()

# Step 5: Get target table columns from Snowflake
cur.execute("DESC TABLE HOLDINGSDETAILS")
column_info = cur.fetchall()
target_columns = [col[0] for col in column_info]

# Step 6: Reorder dataframe to match Snowflake table column order
df = df[[col for col in target_columns if col in df.columns]]

# Step 7: Upsert name fields using MERGE by PORTFOLIOCODE + TICKER
row_count = 0
for _, row in df.iterrows():
    row_data = tuple(row)
    column_list = ','.join(df.columns)

    # Fields to update only
    update_fields = ['ISSUERNAME', 'ISSUENAME', 'ISSUEDISPLAYNAME']
    update_assignments = ', '.join([f'T.{col} = S.{col}' for col in update_fields])

    # MERGE SQL with inline table from Python row
    merge_query = f"""
    MERGE INTO HOLDINGSDETAILS T
    USING (SELECT {','.join(['%s AS ' + col for col in df.columns])}) S
    ON T.PORTFOLIOCODE = S.PORTFOLIOCODE AND T.TICKER = S.TICKER
    WHEN MATCHED THEN UPDATE SET {update_assignments}
    WHEN NOT MATCHED THEN INSERT ({column_list}) VALUES ({','.join(['S.' + col for col in df.columns])})
    """

    cur.execute(merge_query, row_data)
    row_count += 1
    if row_count % 100 == 0:
        print(f"🔄 Upserted {row_count} rows...")

print(f"✅ Done. Total rows processed: {row_count}")

# Step 8: Cleanup
cur.close()
conn.close()